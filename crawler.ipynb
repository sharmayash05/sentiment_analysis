{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests openpyxl html5lib bs4 pandas nltk textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import cmudict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yashy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\yashy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\yashy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('cmudict')\n",
    "syllable_dict = cmudict.dict()\n",
    "\n",
    "# Load stop words from the uploaded files\n",
    "stop_words = set()\n",
    "positive_words = set()\n",
    "negative_words = set()\n",
    "\n",
    "stop_lst = ['StopWords/StopWords_Auditor.txt', 'StopWords/StopWords_Names.txt',\n",
    "            'StopWords/StopWords_DatesandNumbers.txt','StopWords/StopWords_Currencies.txt',\n",
    "            'StopWords/StopWords_Generic.txt','StopWords/StopWords_GenericLong.txt',\n",
    "            'StopWords/StopWords_Geographic.txt']\n",
    "\n",
    "for filename in stop_lst:\n",
    "    with open(filename, 'r') as file:\n",
    "        stop_words.update(file.read().lower().splitlines())\n",
    "\n",
    "\n",
    "with open('MasterDictionary/positive-words.txt', 'r') as file:\n",
    "    positive_words.update(file.read().splitlines())\n",
    "\n",
    "with open('MasterDictionary/negative-words.txt', 'r') as file:\n",
    "    negative_words.update(file.read().splitlines())\n",
    "\n",
    "# Define text analysis functions\n",
    "def clean_text(text):\n",
    "    cleaned_words=[]\n",
    "    words = word_tokenize(text)\n",
    "    for word in words:\n",
    "        if word.isalpha() and (word.lower() not in stop_words):\n",
    "            cleaned_words.append(word.lower())\n",
    "    return cleaned_words\n",
    "\n",
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    if word in syllable_dict:\n",
    "        syllable_counts = [len([x for x in phoneme if x[-1].isdigit()]) for phoneme in syllable_dict[word]]\n",
    "        return max(syllable_counts) if syllable_counts else 0 \n",
    "    else:\n",
    "        return len(re.findall(r'[aeiouy]+', word))  \n",
    "    \n",
    "def complex_word_count(words_list):\n",
    "    return sum(1 for word in words_list if syllable_count(word) >= 3)\n",
    "\n",
    "def personal_pronoun_count(text):\n",
    "    return len(re.findall(r'\\b(I|we|my|ours|us)\\b', text, re.IGNORECASE))\n",
    "\n",
    "def analyze_text(text):\n",
    "    clean_words = clean_text(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "\n",
    "    # Extracting Derived variables\n",
    "    p_score = sum(1 for word in clean_words if word in positive_words)\n",
    "    n_score = sum(1 for word in clean_words if word in negative_words)\n",
    "    polarity_score = (p_score - n_score) / ((p_score + n_score) + 0.000001)\n",
    "    subjectivity_score = (p_score + n_score) / (len(clean_words) + 0.000001)\n",
    "    \n",
    "    # Analysis of Readability\n",
    "    avg_sentence_length = len(clean_words) / len(sentences)\n",
    "    complex_words_count = complex_word_count(clean_words)\n",
    "    percentage_complex_words = (complex_words_count / len(clean_words)) * 100\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "\n",
    "    avg_words_per_sentence = len(clean_words) / len(sentences)\n",
    "    \n",
    "    word_count = len(clean_words)\n",
    "    syllables_per_word = sum(syllable_count(word) for word in clean_words) / len(clean_words)\n",
    "    avg_word_length = sum(len(word) for word in clean_words) / len(clean_words)\n",
    "    personal_pronouns = personal_pronoun_count(text)\n",
    "    \n",
    "    return {\n",
    "        \"Positive Score\": p_score,\n",
    "        \"Negative Score\": n_score,\n",
    "        \"Polarity Score\": polarity_score,\n",
    "        \"Subjectivity Score\": subjectivity_score,\n",
    "        \"Avg Sentence Length\": avg_sentence_length,\n",
    "        \"Percentage of Complex Words\": percentage_complex_words,\n",
    "        \"Fog Index\": fog_index,\n",
    "        \"Avg Words per Sentence\": avg_words_per_sentence,\n",
    "        \"Complex Word Count\": complex_words_count,\n",
    "        \"Word Count\": word_count,\n",
    "        \"Syllable per Word\": syllables_per_word,\n",
    "        \"Personal Pronouns\": personal_pronouns,\n",
    "        \"Avg Word Length\": avg_word_length\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extracted_data = []\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='crawler.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "df = pd.read_excel('Input.xlsx')\n",
    "\n",
    "os.makedirs(\"extracted_txt_folder\", exist_ok=True)\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "\n",
    "    for attempt in range(5):  # Retry for 5 times\n",
    "        try:\n",
    "            \n",
    "            response = requests.get(url, timeout=30)\n",
    "            response.raise_for_status()  \n",
    "            \n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html5lib')\n",
    "\n",
    "           \n",
    "            title = soup.find('h1')\n",
    "            title_text = title.get_text(strip=True) if title else \"No Title Found\"\n",
    "\n",
    "            \n",
    "            article_content = soup.find('div', class_='td-post-content')\n",
    "            if article_content:\n",
    "\n",
    "                article_text_lines=[]\n",
    "\n",
    "                paragraphs = article_content.find_all('p')\n",
    "\n",
    "                for p in paragraphs:\n",
    "                    if p.get_text(strip=True).lower().startswith(\"summarized\"):\n",
    "                            break\n",
    "                    \n",
    "                    article_text_lines.append(p.get_text(strip=True))\n",
    "\n",
    "                article_text = \"\\n\".join(article_text_lines)\n",
    "\n",
    "            else:\n",
    "                article_text = 'No Article Text Found'\n",
    "\n",
    "            file_txt=f\"extracted_txt_folder/{url_id}.txt\"\n",
    "            with open(file_txt, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(f\"Title: {title_text}\\n\\n\")\n",
    "                file.write(article_text)\n",
    "\n",
    "            analysed_data = analyze_text(article_text)\n",
    "            extracted_data.append({\n",
    "                'URL_ID': url_id,\n",
    "                'Title': title_text,\n",
    "                 **analysed_data })\n",
    "            \n",
    "\n",
    "            logging.info(f\"Article with URL_ID {url_id} saved successfully.\")\n",
    "            time.sleep(2)  #Fixed wait_time of 2 seconds after a successful request for handling errors(response time reset etc)\n",
    "            break  \n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Attempt {attempt + 1} failed for URL_ID {url_id}. Error: {e}\")\n",
    "\n",
    "            if attempt == 4:  # If it's the last attempt\n",
    "                logging.error(f\"Failed to retrieve article with URL_ID {url_id} after multiple attempts. Skipping this URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame from the extracted data\n",
    "output_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Save the extracted data to a new Excel file\n",
    "output_df.to_excel(\"Output Data Structure.xlsx\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147 entries, 0 to 146\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   URL_ID                       147 non-null    object \n",
      " 1   Title                        147 non-null    object \n",
      " 2   Positive Score               147 non-null    int64  \n",
      " 3   Negative Score               147 non-null    int64  \n",
      " 4   Polarity Score               147 non-null    float64\n",
      " 5   Subjectivity Score           147 non-null    float64\n",
      " 6   Avg Sentence Length          147 non-null    float64\n",
      " 7   Percentage of Complex Words  147 non-null    float64\n",
      " 8   Fog Index                    147 non-null    float64\n",
      " 9   Avg Words per Sentence       147 non-null    float64\n",
      " 10  Complex Word Count           147 non-null    int64  \n",
      " 11  Word Count                   147 non-null    int64  \n",
      " 12  Syllable per Word            147 non-null    float64\n",
      " 13  Personal Pronouns            147 non-null    int64  \n",
      " 14  Avg Word Length              147 non-null    float64\n",
      "dtypes: float64(8), int64(5), object(2)\n",
      "memory usage: 17.4+ KB\n"
     ]
    }
   ],
   "source": [
    "output_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>Subjectivity Score</th>\n",
       "      <th>Avg Sentence Length</th>\n",
       "      <th>Percentage of Complex Words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Avg Words per Sentence</th>\n",
       "      <th>Complex Word Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllable per Word</th>\n",
       "      <th>Personal Pronouns</th>\n",
       "      <th>Avg Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Netclan20241159</td>\n",
       "      <td>Population and Community Survey of America</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.045752</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>34.858388</td>\n",
       "      <td>19.343355</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>160</td>\n",
       "      <td>459</td>\n",
       "      <td>2.313725</td>\n",
       "      <td>3</td>\n",
       "      <td>6.825708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Netclan20241160</td>\n",
       "      <td>Google LSA API Data Automation and Dashboarding</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.049451</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>35.302198</td>\n",
       "      <td>18.670879</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>257</td>\n",
       "      <td>728</td>\n",
       "      <td>2.262363</td>\n",
       "      <td>7</td>\n",
       "      <td>6.671703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Netclan20241161</td>\n",
       "      <td>Healthcare Data Analysis</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>88</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>11</td>\n",
       "      <td>6.579545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Netclan20241162</td>\n",
       "      <td>Budget, Sales KPI Dashboard using Power BI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Netclan20241163</td>\n",
       "      <td>Amazon Buy Bot, an Automation AI tool to Auto-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>35.849057</td>\n",
       "      <td>17.368194</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "      <td>2.226415</td>\n",
       "      <td>1</td>\n",
       "      <td>6.603774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              URL_ID                                              Title  \\\n",
       "142  Netclan20241159         Population and Community Survey of America   \n",
       "143  Netclan20241160    Google LSA API Data Automation and Dashboarding   \n",
       "144  Netclan20241161                           Healthcare Data Analysis   \n",
       "145  Netclan20241162         Budget, Sales KPI Dashboard using Power BI   \n",
       "146  Netclan20241163  Amazon Buy Bot, an Automation AI tool to Auto-...   \n",
       "\n",
       "     Positive Score  Negative Score  Polarity Score  Subjectivity Score  \\\n",
       "142              12               9        0.142857            0.045752   \n",
       "143              19              17        0.055556            0.049451   \n",
       "144               5               6       -0.090909            0.125000   \n",
       "145               0               0        0.000000            0.000000   \n",
       "146               2               0        1.000000            0.037736   \n",
       "\n",
       "     Avg Sentence Length  Percentage of Complex Words  Fog Index  \\\n",
       "142            13.500000                    34.858388  19.343355   \n",
       "143            11.375000                    35.302198  18.670879   \n",
       "144             8.000000                    25.000000  13.200000   \n",
       "145             8.000000                    75.000000  33.200000   \n",
       "146             7.571429                    35.849057  17.368194   \n",
       "\n",
       "     Avg Words per Sentence  Complex Word Count  Word Count  \\\n",
       "142               13.500000                 160         459   \n",
       "143               11.375000                 257         728   \n",
       "144                8.000000                  22          88   \n",
       "145                8.000000                   6           8   \n",
       "146                7.571429                  19          53   \n",
       "\n",
       "     Syllable per Word  Personal Pronouns  Avg Word Length  \n",
       "142           2.313725                  3         6.825708  \n",
       "143           2.262363                  7         6.671703  \n",
       "144           2.090909                 11         6.579545  \n",
       "145           4.625000                  0        13.375000  \n",
       "146           2.226415                  1         6.603774  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
